<!DOCTYPE html>
<html lang="en"><head>  
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta charset="utf-8">
  <title>Computer Vision Course Project
  | ECE, Virginia Tech | Fall 2025: ECE 4554/5554</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="Enhancing Plant Disease Detection using Computer Vision Algorithms Project Proposal">
  <meta name="author" content="Steven An, Vikram Muruganandam, Youngjoon Park">


<!-- Le styles -->  
  <link href="css/bootstrap.css" rel="stylesheet">
<style>
body {
padding-top: 60px; /* 60px to make the container go all the way to the bottom of the topbar */
}
.vis {
color: #3366CC;
}
.data {
color: #FF9900;
}
</style>
  
<link href="css/bootstrap-responsive.min.css" rel="stylesheet">

<!-- HTML5 shim, for IE6-8 support of HTML5 elements --><!--[if lt IE 9]>
<script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
<![endif]-->
</head>

<body>
<div class="container">
<div class="page-header">

<img src="diseased_plant.jpg" alt="Image of diseased plant leaf.">

<!-- Title and Name --> 
<h1>Comparative Analysis of Advanced Deep Learning Architectures for Multi-Class Plant Disease Detection</h1> 
<span style="font-size: 20px; line-height: 1.5em;"><strong>Steven An, Vikram Muruganandam, Youngjoon Park</strong></span><br>
<span style="font-size: 18px; line-height: 1.5em;">ECE 4554/5554 Computer Vision: Course Project, Fall 2025</span><br>
<span style="font-size: 18px; line-height: 1.5em;">Virginia Tech</span>
<hr>
<span style="font-size: 20px; line-height: 1.5em;">The code for this project can be found on <a href="https://github.com/ECE-4554-Computer-Vision-Group-Project/Code.git">GitHub, here</a>.</span><br>
<hr>

<!-- Goal -->
<h3>Abstract</h3>
<p>
Plant diseases remain a critical threat to global food security, making early and accurate diagnosis essential for effective
crop management. While traditional manual identification is labor intensive and prone to error, deep learning offers a scalable solution for automated detection.
This project evaluates and compares the performance of four state-of-the-art convolutional neural network (CNN) architectures - ResNet50, EfficientNetV2-S, MobileNetV3,
and YOLOv8 - in the classification of 23 healthy and diseased plant categories. Utilizing a transfer learning approach, we leveraged models pre-trained on ImageNet to overcome
data scarcity and computational constraints. The study involve rigorous data preprocessing, including resizing and normalization specific to each architecture, alongside data 
augmentation to improve generalization. Performance was benchmarked using validation accuracy, loss metrics, and inference speed. the results aim to identify the optimal balance between
computational efficiency and classification accuracy, determining which architecture is best suited for real-world agricultural deployment where both precision and speed are critical.
</p>
<br>

<!-- Teaser Figure  -->
<h3>Teaser figure</h3>
<p><p>
<!-- <br><br> -->

<!-- Main Illustrative Figure -->
<div style="text-align: center;">
<img style="height: 200px;" alt="" src="teaser_figure.png">
<p style="text-align: left;">As seen in the image above, the image of the apple leaf as been classified as diseased (scabbed).<p>
</div>
 
<!-- Introduction -->
<h3>Introduction</h3>

<p> 
Plant diseases pose one of the largest threads to global agriculture, impacting food security worldwide through reduced crop yields and causing enormous economic losses. Accurate detection of these
diseases on a large scalae is critical in ensuring these diseases are caught as soon as possible and before they can cause significant damage. Traditional methods such as manual human inspection are often time consming and labor intensive,
making it harder to implement regular checking at large scales. Using machine learning to perform these tasks is significantly cheaper, and does not have the same downsides as human inspection. However, ML models often lack accuracy and without a human 
in the loop to take acountability and due to the financial consequences of a malfunction, many users are hesitant to implement this technology. One method around this is to create and curating models that can achiever higher accuracies in plant desease detection.

</p>

<p>
To do this, project builds upon existing plant disease detection systems by implementing training various models to perform plant desease detction using the same
dataset. Then, we will compare the performance of these models to each other, and to previous work implementing a plant desease detection by <a href="https://www.kaggle.com/code/atharvaingle/plant-disease-classification-resnet-99-2/notebook">Atharva Ingle found here</a>,
that implements plant desease classification using RESNET-9. This model was able to achieve an accuracy of 99.2%, using a similar dataset. We aim to exceed this accuracy using one or more of the models we will be evaluating in this report.
</p>

<br>
<!-- Approach -->
<h3>Approach</h3>
<p>
  The team will build on an existing plant disease detection system that uses a Convolutional Neural Network (CNN) 
  for image classification. Instead of creating a new model, the focus will be on using various methods of image preprocessing
  to improve the detection rate.
</p>
<p>
  Two training pipelines will be used: one with raw images as the baseline, and another with images processed
  using computer vision techniques such as color space transformation, Sobel, Canny, and Laplacian 
  edge detection, histogram equalization, texture analysis. The same CNN architecture will be used for both to ensure a fair
  comparison between differently processed images.
</p>
<p>
  The goal is to find out the extent to which different preprocessing steps improve the model's accuracy and reliability. 
  The main challenge will be adjusting these methods to enhance disease features without distorting the image and making it 
  unrecognizable to the model.Visualization tools like Grad-CAM will be used to confirm whether preprocessing helps the 
  model correctly focus diseased areas.
</p>
<br>

<!-- Plans -->
<h3>Plans for Experimantation</h3>
<p>
  The team will begin the project by using two publicly available datasets found through Kaggle: PlantVillage 
  and New Plant Diseases Dataset. Both datasets contain labeled RGB images of healthy and diseased crop leaves
  across multiple plant species. Each dataset has approximately 87,000 images categorized into 38 different classes, 
  divided into 80% training and 20% validation sets. Both datasets were created through offline augmentation 
  from the original PlantVillage dataset, ensuring balanced class representation and good variety in lighting 
  and leaf position. A separate set of 33 test images is also provided for final evaluation.
</p>
<p>
  These datasets are well-suited for plant disease classification tasks and will serve as the foundation for 
  testing how different preprocessing techniques affect deep learning performance. The datasets already provide
  sufficient diversity in plant type, health condition, and image quality.
</p>
<p>
  The team will build on an existing implementation from Kaggle titled <a href="https://www.kaggle.com/datasets/vipoooool/new-plant-diseases-dataset" >“Plant Disease Classification - ResNet (99.2%)” 
  by Samir Bhattarai</a>, which uses a ResNet-9 architecture trained in PyTorch. This notebook demonstrates 
  how a convolutional neural network can achieve high accuracy on the PlantVillage dataset. We will use 
  this code as our baseline model and compare its performance to our own modified pipeline that includes
  added preprocessing methods.
</p>
<p>
  All preprocessing and experiment scripts will be written by the team using Python and OpenCV for image 
  processing. The model training and evaluation will be done using PyTorch, and experiments will run on Google 
  Colab, local system, or VT Advanced Research Center (ARC). We will record training accuracy, validation accuracy, loss curves, 
  and visualizations for analysis.
</p>

<br>

<h4>
  Project Outline
</h4>
<ol>
  <li><strong>Experimental Setup</strong>
    <ul>
      <li>
        Datasets: PlantVillage and New Plant Diseases Dataset
      </li>
      <li>
        Model Architecture: ResNet-9
      </li>
      <li>
        Implementation Tools: Python, Google Colab/Jupyter Notebook, PyTorch, OpenCV, NumPy, Matplotlib
      </li>
      <li>
        Hardware: Google Colab GPU, local system, or VT Advanced Research Center (ARC)
      </li>
      <li>
        Evaluation Metrics: Accuracy, Precision, Recall, F1-score, and Confusion Matrix
      </li>
    </ul>
  </li>

  <br>

  <li><strong>List of Experiments</strong>
    <ul>
      <li>
        Baseline Model: Reproduce the ResNet-9 results using the original Kaggle code and dataset.
      </li>
      <li>
        Color Space Comparison: Test RGB, HSV, and LAB color-space transformations to analyze which color representation improves classification.
      </li>
      <li>
        Noise Reduction Study: Apply Gaussian and median filters to evaluate how removing background noise affects accuracy.      </li>
      <li>
        Contrast and Edge Enhancement: Use histogram equalization, Sobel/Laplacian filters, and basic texture analysis to highlight disease features.
      </li>
      <li>
        Combined Preprocessing Pipeline: Combine the best-performing preprocessing steps and compare its results against the baseline model.
      </li>
    </ul>
  </li>

  <br>

  <li><strong>Expected Outcomes</strong>
    <ul>
      <li>
        The team expects that adding preprocessing techniques will lead to improved accuracy and more 
        consistent predictions compared to the baseline ResNet-9 model trained on raw images. 
        Visualization results are expected to show that enhanced preprocessing helps the model detect and
        focus on diseased areas more accurately. However, it is uncertain which individual techniques 
        will have the greatest effect, or whether combining multiple methods will cause
        over-enhancement that reduces performance due to straying too far away from the images the model was
        trained on.
      </li>
    </ul>
  </li>

  <br>

  <li><strong>Definition of Success</strong>
    <ul>
      <li>
        The modified preprocessing pipeline achieves higher accuracy than the baseline ResNet-9 model.
      </li>
      <li>
        Visualizations show better focus on diseased leaf areas.
      </li>
      <li>
        The results clearly demonstrate that computer vision-based preprocessing can improve model 
        reliability and overall performance in plant disease detection.
      </li>
    </ul>
  </li>
</ol>

<br><br>

<!-- Main Results Figure
<div style="text-align: center;">
<img style="height: 300px;" alt="" src="results.png">
</div>
<br><br>
--> 

<!-- Results 
<h3>Qualitative results</h3>
Show several visual examples of inputs/outputs of your system (success cases and failures) that help us better understand your approach.
<br><br>
-->

<!-- Main Results Figure 
<div style="text-align: center;">
<img style="height: 300px;" alt="" src="qual_results.png">
</div>
<br><br>
--> 

<!-- Conclusion  -->
<h3>Conclusion</h3>

<br><br>


<!-- References -->
<h3>References</h3>
<h4>Sources</h4>
Previous work: 
<br>
https://www.kaggle.com/code/atharvaingle/plant-disease-classification-resnet-99-2/notebook
<br> <br>
Dataset: 
<br>
https://www.kaggle.com/datasets/karagwaanntreasure/plant-disease-detection/data
<br> <br>
<h4>References</h4>
<br>
<br><br>


  <hr>
  <footer> 
  <p style="font-size: 15px;">To see this project's proposal, click <a href="project_proposal.html">here</a> </p>
  <p>©2025 Steven An, Vikram Muruganandam, Youngjoon Park</p>
  </footer>
</div>
</div>

<br><br>

</body></html>